{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 설명"
      ],
      "metadata": {
        "id": "GbufoPeItBAy"
      },
      "id": "GbufoPeItBAy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "좋아, 팀원들이 쉽게 이해할 수 있도록 **`perfume_model_api.ipynb` 전체 구조**를 각 블록마다 설명을 붙여 정리해줄게. 이건 마크다운 셀로 노트북에 붙이면 그대로 사용 가능해.\n",
        "\n",
        "---\n",
        "\n",
        "# 💡 향수 추천 모델 전체 구조 설명 (`perfume_model_api.ipynb`)\n",
        "\n",
        "## 1. ✅ 라이브러리 임포트 및 재현성 고정\n",
        "\n",
        "```python\n",
        "import os, random, pickle\n",
        "import numpy as np\n",
        "...\n",
        "tf.random.set_seed(42)\n",
        "```\n",
        "\n",
        "* 데이터 처리 및 모델 학습에 필요한 주요 라이브러리를 불러오고,\n",
        "* 결과의 **일관성**을 위해 seed를 고정합니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. 📦 데이터 로딩 및 전처리\n",
        "\n",
        "```python\n",
        "df = pd.read_csv('./data/dataset.csv')\n",
        "...\n",
        "df['notes'] = df['notes'].apply(clean_notes)\n",
        "```\n",
        "\n",
        "* `.csv` 파일에서 향수 데이터를 불러오고,\n",
        "* `notes` 필드를 정제합니다 (불필요한 기호/공백 제거 등).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. 🧪 향료 벡터화\n",
        "\n",
        "```python\n",
        "note_vectorizer = CountVectorizer(token_pattern=r'[^,]+')\n",
        "...\n",
        "note_df = pd.DataFrame(...)\n",
        "```\n",
        "\n",
        "* `notes`(향료 목록)를 Bag-of-Words 방식으로 벡터화합니다.\n",
        "* 각 향수마다 향료 출현 여부가 벡터로 표현됩니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. 🧠 입력값 인코딩\n",
        "\n",
        "```python\n",
        "encoder = OrdinalEncoder()\n",
        "...\n",
        "X = encoder.transform(...)\n",
        "```\n",
        "\n",
        "* 성별, 계절, 시간대 등의 **카테고리 특성**을 숫자로 인코딩합니다.\n",
        "* OneHot이 아닌 **OrdinalEncoder**를 사용해 의미론적 거리 반영.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. 🧩 학습 데이터 분할 및 클래스 가중치 계산\n",
        "\n",
        "```python\n",
        "X_train, X_val, y_train, y_val = ...\n",
        "class_weights = compute_class_weight(...)\n",
        "```\n",
        "\n",
        "* 전체 데이터를 **학습/검증**으로 나누고,\n",
        "* 불균형한 감정 클래스 문제를 해결하기 위해 **클래스별 가중치**를 계산합니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. 🏗️ 모델 정의 및 학습\n",
        "\n",
        "```python\n",
        "model = Sequential([...])\n",
        "model.compile(...)\n",
        "model.fit(...)\n",
        "```\n",
        "\n",
        "* 심플한 Dense(64) 구조의 **MLP 모델**을 정의합니다.\n",
        "* `EarlyStopping`으로 과적합 방지, 클래스 가중치 적용.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. 🧾 모델 성능 평가\n",
        "\n",
        "```python\n",
        "y_pred = ...\n",
        "results = {\n",
        "    \"classification_report\": ...,\n",
        "    \"macro_f1\": ...,\n",
        "    \"weighted_f1\": ...\n",
        "}\n",
        "```\n",
        "\n",
        "* 검증 데이터를 이용해 **정밀도, 재현율, F1 점수**를 계산합니다.\n",
        "* 추후 분석을 위한 JSON 형태로 저장.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. 💾 모델 및 도구 저장\n",
        "\n",
        "```python\n",
        "model.save(...)\n",
        "pickle.dump(...)\n",
        "note_df.to_csv(...)\n",
        "```\n",
        "\n",
        "* 학습이 완료된 모델 및 인코더, 벡터라이저를 `.keras`, `.pkl`, `.csv` 형태로 저장.\n",
        "* API 서버에서 바로 로딩 가능하게 구성됨.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. 🔍 감정 예측 함수 (`predict_emotion`)\n",
        "\n",
        "```python\n",
        "def predict_emotion(user_input):\n",
        "    ...\n",
        "    return {\n",
        "        \"cluster\": pred,\n",
        "        \"description\": EMOTION_DESC[pred],\n",
        "        \"proba\": proba.tolist()\n",
        "    }\n",
        "```\n",
        "\n",
        "* 사용자의 태그 입력을 바탕으로 **감정 클러스터를 예측**하고,\n",
        "* 감정 설명(`description`)과 확률 분포(`proba`)를 반환.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. 📝 주요 노트 추출 함수 (`extract_notes`)\n",
        "\n",
        "```python\n",
        "def extract_notes(...):\n",
        "    ...\n",
        "    return 상위 노트 리스트, 1차 추천 향수 인덱스\n",
        "```\n",
        "\n",
        "* 예측된 감정 클러스터에 기반해 **대표적인 노트 15개**를 추출.\n",
        "* 향수 벡터 간 유사도를 활용해 **중복되지 않는 향수 10개**도 선택.\n",
        "\n",
        "---\n",
        "\n",
        "## 11. 🌸 향수 재추천 함수 (`recommend_perfumes`)\n",
        "\n",
        "```python\n",
        "def recommend_perfumes(...):\n",
        "    ...\n",
        "    return 추천 향수 리스트 (JSON 딕셔너리)\n",
        "```\n",
        "\n",
        "* 사용자가 선택한 **노트 선호도 점수**를 받아,\n",
        "* 감정 + 노트 기반의 `final_score`로 2차 향수 추천을 수행.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 연동 포인트 요약\n",
        "\n",
        "| 목적        | 설명                                          |\n",
        "| --------- | ------------------------------------------- |\n",
        "| 프론트 입력    | `user_input`: 태그 6개                         |\n",
        "| 1차 호출 API | `/predict_emotion`: 감정 클러스터 + 설명 + proba 반환 |\n",
        "| 노트 선택 이후  | `/recommend_perfumes`: 추천 향수 10개 반환         |\n",
        "| 결과 포맷     | `JSON` 형태로 API 응답 가능                        |\n",
        "\n",
        "---\n",
        "\n",
        "필요하면 이 설명을 `.ipynb` 내부 마크다운 셀로 만들어서 추가해줄 수 있어. 원할 때 말해줘!\n"
      ],
      "metadata": {
        "id": "nMQuy9tAtJeH"
      },
      "id": "nMQuy9tAtJeH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델"
      ],
      "metadata": {
        "id": "rRp9o7OssHRQ"
      },
      "id": "rRp9o7OssHRQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e3b339",
      "metadata": {
        "id": "02e3b339"
      },
      "outputs": [],
      "source": [
        "\n",
        "# perfume_model_api.ipynb\n",
        "# ✅ API 연동용으로 리팩토링됨\n",
        "\n",
        "import os, random, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 재현성 고정\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "df = pd.read_csv('./data/dataset.csv')\n",
        "df['notes'] = df['notes'].fillna('').str.lower()\n",
        "\n",
        "def clean_notes(raw_notes):\n",
        "    notes = [n.strip() for n in raw_notes.split(',')]\n",
        "    return ', '.join([n for n in notes if len(n) > 0 and len(n) < 40])\n",
        "\n",
        "df['notes'] = df['notes'].apply(clean_notes)\n",
        "\n",
        "note_vectorizer = CountVectorizer(token_pattern=r'[^,]+')\n",
        "note_matrix = note_vectorizer.fit_transform(df['notes'])\n",
        "note_df = pd.DataFrame(note_matrix.toarray(), columns=note_vectorizer.get_feature_names_out())\n",
        "\n",
        "# 인코딩 및 분할\n",
        "encoder = OrdinalEncoder()\n",
        "X_input = df[['gender', 'season_tags', 'time_tags', 'desired_impression', 'activity', 'weather']]\n",
        "encoder.fit(X_input.values)\n",
        "X = encoder.transform(X_input.values)\n",
        "y = df['emotion_cluster']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {i: w for i, w in zip(np.unique(y_train), class_weights)}\n",
        "\n",
        "# 모델 정의\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[early_stop], class_weight=class_weight_dict)\n",
        "\n",
        "# 성능 평가\n",
        "y_pred = model.predict(X_val).argmax(axis=1)\n",
        "results = {\n",
        "    \"classification_report\": classification_report(y_val, y_pred, output_dict=True),\n",
        "    \"macro_f1\": f1_score(y_val, y_pred, average='macro'),\n",
        "    \"weighted_f1\": f1_score(y_val, y_pred, average='weighted')\n",
        "}\n",
        "results\n",
        "\n",
        "# 저장\n",
        "model.save('./models/final_model.keras')\n",
        "with open('./models/encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(encoder, f)\n",
        "with open('./models/note_vectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(note_vectorizer, f)\n",
        "note_df.to_csv('./data/note_df.csv', index=False)\n",
        "\n",
        "# 추론 함수 정의\n",
        "EMOTION_DESC = {\n",
        "    0: \"따뜻하고 친근한 감정\",\n",
        "    1: \"신선하고 활기찬 느낌\",\n",
        "    2: \"우아하고 세련된 분위기\",\n",
        "    3: \"관능적이고 매혹적인 향\",\n",
        "    4: \"부드럽고 순수한 감정\",\n",
        "    5: \"신비롭고 독특한 감정\"\n",
        "}\n",
        "\n",
        "def predict_emotion(user_input):\n",
        "    encoder = pickle.load(open('./models/encoder.pkl', 'rb'))\n",
        "    model = load_model('./models/final_model.keras')\n",
        "    user_vec = encoder.transform([user_input])\n",
        "    proba = model.predict(user_vec)[0]\n",
        "    pred = int(np.argmax(proba))\n",
        "    return {\n",
        "        \"cluster\": pred,\n",
        "        \"description\": EMOTION_DESC[pred],\n",
        "        \"proba\": proba.tolist()\n",
        "    }\n",
        "\n",
        "def extract_notes(df, note_df, proba):\n",
        "    df['emotion_score'] = df['emotion_cluster'].map(lambda c: proba[c])\n",
        "    selected = []\n",
        "    top_sorted = df.sort_values('emotion_score', ascending=False)\n",
        "    for i in top_sorted.index:\n",
        "        if all(cosine_similarity([note_df.loc[i]], [note_df.loc[j]])[0][0] < 0.95 for j in selected):\n",
        "            selected.append(i)\n",
        "        if len(selected) == 10:\n",
        "            break\n",
        "    top_perfumes = df.loc[selected]\n",
        "    top_notes_matrix = note_df.loc[top_perfumes.index]\n",
        "    top_notes_sum = top_notes_matrix.sum(axis=0)\n",
        "    return top_notes_sum.sort_values(ascending=False).head(15).index.tolist(), selected\n",
        "\n",
        "def recommend_perfumes(df, note_df, user_note_scores, selected_idx, proba):\n",
        "    user_note_vec = np.zeros((1, len(note_df.columns)))\n",
        "    for i, note in enumerate(note_df.columns):\n",
        "        score = user_note_scores.get(note, 0)\n",
        "        user_note_vec[0, i] = score / 5\n",
        "    note_cos_sim = cosine_similarity(note_df.values, user_note_vec).reshape(-1)\n",
        "    note_sum = np.zeros(len(note_df))\n",
        "    for note, weight in user_note_scores.items():\n",
        "        if note in note_df.columns:\n",
        "            note_sum += note_df[note].to_numpy().ravel() * weight\n",
        "    note_score = 0.7 * note_cos_sim + 0.3 * (note_sum / 10)\n",
        "    df['note_score'] = note_score\n",
        "    df['is_top10'] = df.index.isin(selected_idx).astype(int)\n",
        "    df['emotion_score'] = df['emotion_cluster'].map(lambda c: proba[c])\n",
        "    df['final_score'] = 0.7 * df['emotion_score'] + 0.25 * df['note_score'] + 0.05 * df['is_top10']\n",
        "    df['note_diversity'] = note_df.astype(bool).sum(axis=1)\n",
        "    top10 = df.sort_values(by=['final_score', 'note_diversity'], ascending=[False, False]).head(10)\n",
        "    return top10[['name', 'brand', 'final_score', 'emotion_cluster']].to_dict(orient='records')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}